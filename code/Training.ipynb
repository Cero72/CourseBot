{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers datasets accelerate bitsandbytes torch peft trl PyPDF2 scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login --token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T22:19:32.989156Z",
     "iopub.status.busy": "2024-12-05T22:19:32.988888Z",
     "iopub.status.idle": "2024-12-05T22:19:52.175377Z",
     "shell.execute_reply": "2024-12-05T22:19:52.174689Z",
     "shell.execute_reply.started": "2024-12-05T22:19:32.989131Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, logging as transformers_logging\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "\n",
    "transformers_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T22:19:52.177488Z",
     "iopub.status.busy": "2024-12-05T22:19:52.177224Z",
     "iopub.status.idle": "2024-12-05T22:19:52.182073Z",
     "shell.execute_reply": "2024-12-05T22:19:52.181182Z",
     "shell.execute_reply.started": "2024-12-05T22:19:52.177462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "os.makedirs(\"models/checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"models/final\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T22:19:52.183530Z",
     "iopub.status.busy": "2024-12-05T22:19:52.183191Z",
     "iopub.status.idle": "2024-12-05T22:19:52.963551Z",
     "shell.execute_reply": "2024-12-05T22:19:52.962520Z",
     "shell.execute_reply.started": "2024-12-05T22:19:52.183495Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_model():\n",
    "   bnb_config = BitsAndBytesConfig(\n",
    "       load_in_4bit=True,\n",
    "       bnb_4bit_quant_type=\"nf4\",\n",
    "       bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "       bnb_4bit_use_double_quant=False\n",
    "   )\n",
    "   \n",
    "   model = AutoModelForCausalLM.from_pretrained(\n",
    "       \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "       quantization_config=bnb_config,\n",
    "       device_map=\"auto\",\n",
    "       torch_dtype=torch.bfloat16,\n",
    "       trust_remote_code=True\n",
    "   )\n",
    "   \n",
    "   tokenizer = AutoTokenizer.from_pretrained(\n",
    "       \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "       trust_remote_code=True\n",
    "   )\n",
    "   tokenizer.pad_token = tokenizer.eos_token\n",
    "   tokenizer.padding_side = \"right\"\n",
    "   \n",
    "   model.gradient_checkpointing_enable()\n",
    "   model.enable_input_require_grads()\n",
    "   \n",
    "   return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T22:19:52.965074Z",
     "iopub.status.busy": "2024-12-05T22:19:52.964749Z",
     "iopub.status.idle": "2024-12-05T22:19:52.975811Z",
     "shell.execute_reply": "2024-12-05T22:19:52.974914Z",
     "shell.execute_reply.started": "2024-12-05T22:19:52.965048Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_lora(model):\n",
    "   lora_config = LoraConfig(\n",
    "       r=64,\n",
    "       lora_alpha=128,\n",
    "       target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\", \n",
    "                    \"mlp.gate_proj\", \"mlp.up_proj\", \"mlp.down_proj\"],\n",
    "       lora_dropout=0.1,\n",
    "       bias=\"none\",\n",
    "       task_type=\"CAUSAL_LM\"\n",
    "   )\n",
    "   return get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T22:19:52.977608Z",
     "iopub.status.busy": "2024-12-05T22:19:52.977008Z",
     "iopub.status.idle": "2024-12-05T22:19:52.987133Z",
     "shell.execute_reply": "2024-12-05T22:19:52.986475Z",
     "shell.execute_reply.started": "2024-12-05T22:19:52.977564Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(df):\n",
    "   formatted_data = []\n",
    "   for _, row in df.iterrows():\n",
    "       formatted_data.append({\n",
    "           \"text\": f\"<s>[INST]@ESE577 Course Question. Provide a detailed answer using course-specific terminology and examples. Question: {row['question']} [/INST]Answer: {row['answer']}</s>\"\n",
    "       })\n",
    "   return Dataset.from_list(formatted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T22:19:52.988238Z",
     "iopub.status.busy": "2024-12-05T22:19:52.988001Z",
     "iopub.status.idle": "2024-12-05T22:19:52.999685Z",
     "shell.execute_reply": "2024-12-05T22:19:52.998826Z",
     "shell.execute_reply.started": "2024-12-05T22:19:52.988215Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class MetricsCallback(TrainerCallback):\n",
    "    def __init__(self, writer):\n",
    "        self.writer = writer\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs:\n",
    "            for k, v in logs.items():\n",
    "                if isinstance(v, (int, float)):\n",
    "                    self.writer.add_scalar(k, v, state.global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T22:19:53.001046Z",
     "iopub.status.busy": "2024-12-05T22:19:53.000725Z",
     "iopub.status.idle": "2024-12-05T22:19:53.011660Z",
     "shell.execute_reply": "2024-12-05T22:19:53.010961Z",
     "shell.execute_reply.started": "2024-12-05T22:19:53.001020Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(train_df, val_df):\n",
    "   model, tokenizer = setup_model()\n",
    "   model = setup_lora(model)\n",
    "   \n",
    "   train_dataset = prepare_dataset(train_df)\n",
    "   val_dataset = prepare_dataset(val_df)\n",
    "   \n",
    "   writer = SummaryWriter(log_dir=\"logs/tensorboard\")\n",
    "   \n",
    "   training_args = TrainingArguments(\n",
    "       output_dir=\"models/checkpoints\",\n",
    "       num_train_epochs=6,\n",
    "       per_device_train_batch_size=2,\n",
    "       gradient_accumulation_steps=32,\n",
    "       learning_rate=3e-4,\n",
    "       warmup_ratio=0.2,\n",
    "       weight_decay=0.1,\n",
    "       bf16=True,\n",
    "       logging_steps=10,\n",
    "       save_strategy=\"epoch\",\n",
    "       evaluation_strategy=\"epoch\",\n",
    "       load_best_model_at_end=True,\n",
    "       optim=\"adamw_torch\",\n",
    "       lr_scheduler_type=\"cosine_with_restarts\",\n",
    "       report_to=[\"tensorboard\"],\n",
    "       logging_dir=\"logs/training\"\n",
    "   )\n",
    "   \n",
    "   trainer = SFTTrainer(\n",
    "       model=model,\n",
    "       train_dataset=train_dataset,\n",
    "       eval_dataset=val_dataset,\n",
    "       tokenizer=tokenizer,\n",
    "       args=training_args,\n",
    "       max_seq_length=1024\n",
    "   )\n",
    "   \n",
    "   trainer.add_callback(MetricsCallback(writer))\n",
    "   \n",
    "   print(\"Starting training...\")\n",
    "   trainer.train()\n",
    "   \n",
    "   print(\"Saving final model...\")\n",
    "   trainer.save_model(\"models/final\")\n",
    "   \n",
    "   writer.close()\n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T22:19:53.014127Z",
     "iopub.status.busy": "2024-12-05T22:19:53.013583Z",
     "iopub.status.idle": "2024-12-05T23:57:30.218412Z",
     "shell.execute_reply": "2024-12-05T23:57:30.216639Z",
     "shell.execute_reply.started": "2024-12-05T22:19:53.014091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Splitting dataset...\n",
      "Training samples: 319\n",
      "Validation samples: 80\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f78a9e606f471fbc54ed4623dc8f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b6e336889b4306b28c0cd796ee5eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea68b1079d44242baaf36ea14c4ab6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d692a1353984fbc8607e7bc69e52631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94791b5dc36b45928940252c312800a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623b7f87c151445cbc23bc5ed09e4a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6162b78741549c6ad339673ccfb2cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510abbf3091841169882a0c72f5ba190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b191b806d94bcbaf665d28e520aeb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6793a0dabe4cd299517dd84d446301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c39a4bbd834ae8b9a11ebd8ba811df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5071507908a422cb706b4c3952d06e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893b704481dc4f5d80a9c5261c278e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54a39e7302243b287165263e9332697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "{'eval_loss': 1.3730199337005615, 'eval_runtime': 60.5827, 'eval_samples_per_second': 1.321, 'eval_steps_per_second': 0.165, 'epoch': 1.0}\n",
      "{'loss': 1.8246, 'grad_norm': 42.466888427734375, 'learning_rate': 0.0002799038105676658, 'epoch': 2.0}\n",
      "{'eval_loss': 1.0979886054992676, 'eval_runtime': 60.5766, 'eval_samples_per_second': 1.321, 'eval_steps_per_second': 0.165, 'epoch': 2.0}\n",
      "{'eval_loss': 1.0811164379119873, 'eval_runtime': 60.5821, 'eval_samples_per_second': 1.321, 'eval_steps_per_second': 0.165, 'epoch': 3.0}\n",
      "{'loss': 0.4099, 'grad_norm': 43.64652633666992, 'learning_rate': 0.00011117714323462186, 'epoch': 4.0}\n",
      "{'eval_loss': 1.410768985748291, 'eval_runtime': 60.5786, 'eval_samples_per_second': 1.321, 'eval_steps_per_second': 0.165, 'epoch': 4.0}\n",
      "{'eval_loss': 1.4830907583236694, 'eval_runtime': 60.5804, 'eval_samples_per_second': 1.321, 'eval_steps_per_second': 0.165, 'epoch': 5.0}\n",
      "{'loss': 0.0884, 'grad_norm': 10.76285171508789, 'learning_rate': 0.0, 'epoch': 6.0}\n",
      "{'eval_loss': 1.5189416408538818, 'eval_runtime': 60.6134, 'eval_samples_per_second': 1.32, 'eval_steps_per_second': 0.165, 'epoch': 6.0}\n",
      "{'train_runtime': 5471.0558, 'train_samples_per_second': 0.35, 'train_steps_per_second': 0.005, 'train_loss': 0.7742837349573771, 'epoch': 6.0}\n",
      "Saving final model...\n",
      "\n",
      "Training completed! Model saved in models/final\n",
      "View training metrics with: tensorboard --logdir=logs/tensorboard\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "   print(\"Loading dataset...\")\n",
    "   train_df = pd.read_csv('/kaggle/input/shuffled-data/shuffled_file.csv')\n",
    "   \n",
    "   print(\"Splitting dataset...\")\n",
    "   train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "   \n",
    "   print(f\"Training samples: {len(train_df)}\")\n",
    "   print(f\"Validation samples: {len(val_df)}\")\n",
    "   \n",
    "   model = train_model(train_df, val_df)\n",
    "   print(\"\\nTraining completed! Model saved in models/final\")\n",
    "   print(\"View training metrics with: tensorboard --logdir=logs/tensorboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "def load_model():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=False\n",
    "    )\n",
    "    \n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    \n",
    "    model = PeftModel.from_pretrained(base_model, \"/kaggle/input/finetuned_model/pytorch/default/1/final\")\n",
    "    return model, tokenizer\n",
    "\n",
    "def generate_response(model, tokenizer, question):\n",
    "    prompt = f\"\"\"<s>[INST]@ESE577. For multiple choice questions:\n",
    "1. Start with \"Answer: [letter]\"\n",
    "2. Reference specific course sections\n",
    "3. Explain using course examples\n",
    "4. Connect to course concepts\n",
    "\n",
    "Question: {question} [/INST]\"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        top_k=40,\n",
    "        num_beams=2,\n",
    "        repetition_penalty=1.1,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response.split(\"[/INST]\")[-1].strip()\n",
    "\n",
    "def chat():\n",
    "   print(\"Loading model...\")\n",
    "   model, tokenizer = load_model()\n",
    "   print(\"Model loaded! Ask your questions (type 'exit' to quit)\")\n",
    "   \n",
    "   while True:\n",
    "       question = input(\"\\nQuestion: \")\n",
    "       if question.lower() == 'exit':\n",
    "           break\n",
    "       try:\n",
    "           response = generate_response(model, tokenizer, question)\n",
    "           print(\"\\nResponse:\")\n",
    "           print(\"=\" * 50)\n",
    "           print(response)\n",
    "       except Exception as e:\n",
    "           print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T00:25:26.209538Z",
     "iopub.status.busy": "2024-12-06T00:25:26.208532Z",
     "iopub.status.idle": "2024-12-06T00:25:26.216773Z",
     "shell.execute_reply": "2024-12-06T00:25:26.215914Z",
     "shell.execute_reply.started": "2024-12-06T00:25:26.209483Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6132297,
     "sourceId": 9968296,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6137390,
     "sourceId": 9975089,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6138550,
     "sourceId": 9976656,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6138728,
     "sourceId": 9976906,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6208641,
     "sourceId": 10072755,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6214574,
     "sourceId": 10080620,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6215662,
     "sourceId": 10082039,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 184184,
     "modelInstanceId": 161816,
     "sourceId": 189792,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
